# ğŸ¤– OpenAI Model SeÃ§imi

Goal Tracker Pro, OpenAI API ile Ã§alÄ±ÅŸmak Ã¼zere yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r. Ä°htiyacÄ±nÄ±za gÃ¶re farklÄ± modeller kullanabilirsiniz.

## ğŸ“Š Desteklenen Modeller

### 1. GPT-4 Turbo (Ã–nerilen) â­
```env
OPENAI_MODEL=gpt-4-turbo-preview
```

**Ã–zellikler:**
- âœ… En geliÅŸmiÅŸ model
- âœ… 128K context window
- âœ… En iyi doÄŸruluk ve anlama
- âœ… Kompleks gÃ¶revler iÃ§in ideal
- âŒ Daha yavaÅŸ
- âŒ Daha pahalÄ± ($0.01/1K tokens input, $0.03/1K tokens output)

**Ne zaman kullanmalÄ±:**
- Production iÃ§in en iyisi
- Kaliteli motivasyon mesajlarÄ±
- DetaylÄ± analiz gerekiyorsa

---

### 2. GPT-4 (Stable)
```env
OPENAI_MODEL=gpt-4
```

**Ã–zellikler:**
- âœ… Ã‡ok gÃ¼venilir
- âœ… Ä°yi performans
- âœ… 8K context window
- âŒ Turbo'dan daha pahalÄ±

---

### 3. GPT-3.5 Turbo (Ekonomik) ğŸ’°
```env
OPENAI_MODEL=gpt-3.5-turbo
```

**Ã–zellikler:**
- âœ… Ã‡ok hÄ±zlÄ±
- âœ… Ã‡ok ucuz ($0.0005/1K tokens input, $0.0015/1K tokens output)
- âœ… 16K context window
- âš ï¸ GPT-4'ten daha az yetenekli
- âš ï¸ Bazen daha genel cevaplar

**Ne zaman kullanmalÄ±:**
- Development/testing iÃ§in
- Budget kÄ±sÄ±tlÄ± ise
- Basit motivasyon mesajlarÄ± yeterli

---

### 4. GPT-3.5 Turbo 16K
```env
OPENAI_MODEL=gpt-3.5-turbo-16k
```

Daha uzun context iÃ§in GPT-3.5 versiyonu.

---

## ğŸ’° Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

### Ã–rnek: 100 AI check-in/gÃ¼n

| Model | Input | Output | GÃ¼nlÃ¼k Maliyet | AylÄ±k Maliyet |
|-------|-------|--------|----------------|---------------|
| GPT-4 Turbo | 500 tokens | 200 tokens | ~$0.11 | ~$3.30 |
| GPT-3.5 Turbo | 500 tokens | 200 tokens | ~$0.01 | ~$0.30 |

**Not:** GerÃ§ek maliyetler kullanÄ±ma gÃ¶re deÄŸiÅŸir.

---

## âš™ï¸ Model DeÄŸiÅŸtirme

### Railway'de:
1. Variables â†’ `OPENAI_MODEL` bulun
2. DeÄŸeri deÄŸiÅŸtirin (Ã¶rn: `gpt-3.5-turbo`)
3. Service otomatik restart olur

### Local'de:
`.env` dosyasÄ±nda:
```env
OPENAI_MODEL=gpt-3.5-turbo
```

Restart:
```bash
npm run dev
```

---

## ğŸ¯ Ã–nerilerimiz

### Production
```env
OPENAI_MODEL=gpt-4-turbo-preview
```
En iyi kullanÄ±cÄ± deneyimi iÃ§in.

### Development/Testing
```env
OPENAI_MODEL=gpt-3.5-turbo
```
HÄ±zlÄ± iterasyon ve dÃ¼ÅŸÃ¼k maliyet.

### Budget-Conscious Production
```env
OPENAI_MODEL=gpt-3.5-turbo
```
Ã‡oÄŸu kullanÄ±m senaryosu iÃ§in yeterli.

---

## ğŸ”§ Advanced: Model Parameters

`src/services/aiService.js` iÃ§inde daha fazla kontrol:

```javascript
const completion = await openai.chat.completions.create({
  model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
  max_tokens: 1024,           // Maksimum response uzunluÄŸu
  temperature: 0.7,           // YaratÄ±cÄ±lÄ±k (0-2, dÃ¼ÅŸÃ¼k = tutarlÄ±)
  top_p: 1,                   // Nucleus sampling
  frequency_penalty: 0,       // Tekrar eden kelimeler
  presence_penalty: 0,        // Yeni topic'ler
  messages: [...]
});
```

### Temperature AyarÄ±

```javascript
temperature: 0.3  // Daha tutarlÄ±, Ã¶ngÃ¶rÃ¼lebilir
temperature: 0.7  // Dengeli (default)
temperature: 1.2  // Daha yaratÄ±cÄ±, Ã§eÅŸitli
```

---

## ğŸ“Š Model Performans Ä°statistikleri

### Response SÃ¼releri (ortalama)

| Model | Check-in | Analysis | Motivation |
|-------|----------|----------|------------|
| GPT-4 Turbo | ~2-3s | ~3-5s | ~2-3s |
| GPT-3.5 Turbo | ~1-2s | ~2-3s | ~1-2s |

---

## ğŸ†• Yeni Modeller

OpenAI sÃ¼rekli yeni modeller yayÄ±nlÄ±yor:

- `gpt-4-turbo` (latest)
- `gpt-4-turbo-2024-04-09` (specific version)
- `gpt-4o` (gelecek model)

GÃ¼ncel liste: [platform.openai.com/docs/models](https://platform.openai.com/docs/models)

---

## ğŸ” Test Etme

Model deÄŸiÅŸtirdikten sonra test edin:

```bash
curl -X POST https://your-app.railway.app/api/ai/check-in \
  -H "Authorization: Bearer YOUR_TOKEN"
```

Response kalitesini ve sÃ¼resini karÅŸÄ±laÅŸtÄ±rÄ±n.

---

## âš ï¸ Limitler

### Rate Limits (Tier 1)

| Model | RPM | TPM |
|-------|-----|-----|
| GPT-4 | 500 | 10,000 |
| GPT-3.5 | 3,500 | 60,000 |

RPM = Requests Per Minute
TPM = Tokens Per Minute

Daha yÃ¼ksek limitler iÃ§in: [platform.openai.com/settings/organization/billing](https://platform.openai.com/settings/organization/billing)

---

## ğŸ“ Best Practices

1. **Development:** GPT-3.5 kullan
2. **Production:** GPT-4 Turbo ile baÅŸla
3. **Monitor:** Maliyetleri takip et
4. **Optimize:** Gerekirse downgrade et
5. **Cache:** SÄ±k kullanÄ±lan responses'larÄ± cache'le (gelecek Ã¶zellik)

---

**VarsayÄ±lan:** `gpt-4-turbo-preview` (en iyi kalite)

Ä°htiyacÄ±nÄ±za gÃ¶re deÄŸiÅŸtirin! ğŸš€

